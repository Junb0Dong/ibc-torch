{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2116e5c",
   "metadata": {},
   "source": [
    "# 2D 实验的notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ec1ad5",
   "metadata": {},
   "source": [
    "这个代码详细的完成一个Implicit的训练和推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec8b257",
   "metadata": {},
   "source": [
    "1. 加载数据集\n",
    "2. 定义模型\n",
    "3. 开始训练\n",
    "4. 评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710068a1",
   "metadata": {},
   "source": [
    "## 加载数据集\n",
    "- 数据集和验证集配置\n",
    "- 分割数据集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4315ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "ibc_parent_dir = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "sys.path.append(ibc_parent_dir)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from ibc import dataset, models, optimizers, trainer, utils\n",
    "from scipy.spatial import ConvexHull\n",
    "from ibc.trainer import PolicyType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6ec31a",
   "metadata": {},
   "source": [
    "许多超参需要调整，在这里调整吧"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639e473a",
   "metadata": {},
   "source": [
    "dataset的超参设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "68a3b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"implicit_pipeline_10\" # experiment name\n",
    "custom_seed = 42\n",
    "\n",
    "train_dataset_size = 10\n",
    "train_batch_size = 8\n",
    "trian_num_workers = 1\n",
    "\n",
    "test_dataset_size = 500\n",
    "test_batch_size = 8\n",
    "test_num_workers = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e04edb",
   "metadata": {},
   "source": [
    "训练的超参设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "01574cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_conv = True # 是否使用坐标卷积？\n",
    "in_channels = 3 # 输入通道数，对应RGB\n",
    "spatial_reduction = models.SpatialReduction.SPATIAL_SOFTMAX\n",
    "policy_type = PolicyType\n",
    "custom_dropout_prob = 0.1\n",
    "custom_learning_rate = 0.001\n",
    "custom_weight_decay = 0.0001\n",
    "\n",
    "# train setting\n",
    "checkpoint_every_n_steps = 100\n",
    "eval_every_n_steps = 1000\n",
    "log_every_n_steps = 10\n",
    "\n",
    "implicit = True # 选择显式or隐式，这个代码现在只支持隐式\n",
    "if implicit:\n",
    "    policy_type = trainer.PolicyType.IMPLICIT\n",
    "else:\n",
    "    policy_type = trainer.PolicyType.EXPLICIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "19f33ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled 1 data points.\n"
     ]
    }
   ],
   "source": [
    "train_dataset_config = dataset.DatasetConfig(\n",
    "    dataset_size=train_dataset_size,\n",
    "    seed=custom_seed, \n",
    "    # 其他参数默认\n",
    ")\n",
    "train_dataset = dataset.CoordinateRegression(train_dataset_config)  # data: coordinate regression shape:（N,2)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=trian_num_workers,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# Test split.\n",
    "test_dataset_config = dataset.DatasetConfig(\n",
    "    dataset_size=test_dataset_size,\n",
    "    seed=custom_seed, \n",
    ")\n",
    "test_dataset = dataset.CoordinateRegression(test_dataset_config)\n",
    "test_dataset.exclude(train_dataset.coordinates) # 防止测试集中包含训练集的数据\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=test_num_workers,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5f2837c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataloader.dataset.get_target_bounds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b52acd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch的类型: <class 'list'>\n",
      "batch包含的元素数量: 2\n",
      "batch[0].shape:torch.Size([8, 3, 96, 96])\n",
      "batch[1].shape:torch.Size([8, 2])\n",
      "target is : tensor([ 0.8105, -0.3895])\n",
      "unscaled target is:  [86. 29.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))    # 可以更改为test_dataloader查看测试集的shape\n",
    "\n",
    "print(\"batch的类型:\", type(batch))  # data + label\n",
    "print(\"batch包含的元素数量:\", len(batch))\n",
    "\n",
    "for i in range(len(batch)):\n",
    "    print(\"batch[{}].shape:{}\".format(i, batch[i].shape))\n",
    "\n",
    "# Visualize one instance.\n",
    "image, target = train_dataset[np.random.randint(len(train_dataset))]\n",
    "print(\"target is :\", target) # target is normalization in [-1, 1]\n",
    "\n",
    "# 坐标缩放\n",
    "target_unscaled = np.array(target)\n",
    "target_unscaled += 1\n",
    "target_unscaled /= 2\n",
    "target_unscaled *= train_dataset.resolution[0] - 1\n",
    "\n",
    "print(\"unscaled target is: \", target_unscaled)\n",
    "\n",
    "plt.imshow(image.permute(1, 2, 0).numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad2ae8b",
   "metadata": {},
   "source": [
    "## 构造网络模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa282f",
   "metadata": {},
   "source": [
    "**配置网络参数**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467c9cfb",
   "metadata": {},
   "source": [
    "网络与优化器配置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "713d7733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in channels: 5\n",
      "input dimension: 34\n"
     ]
    }
   ],
   "source": [
    "if coord_conv: # 如果启用坐标卷积（coord_conv），输入通道数+2（添加x/y坐标通道）\n",
    "    in_channels += 2\n",
    "residual_blocks = [16, 32, 32]  # 3个残差块,通道: 16 32 32\n",
    "cnn_config = models.CNNConfig(in_channels, residual_blocks) # CNN配置\n",
    "print(\"in channels:\", in_channels)\n",
    "\n",
    "input_dim = 16  # 1x1 conv that reduces to 16 channels.\n",
    "output_dim = 2\n",
    "if spatial_reduction == models.SpatialReduction.SPATIAL_SOFTMAX:\n",
    "    input_dim *= 2\n",
    "if policy_type == trainer.PolicyType.IMPLICIT:\n",
    "    input_dim += 2  # Dimension of the targets. o+a\n",
    "    # print(\"input dimension:\", input_dim)\n",
    "    output_dim = 1\n",
    "\n",
    "print(\"input dimension:\", input_dim)\n",
    "\n",
    "mlp_config = models.MLPConfig(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=256,\n",
    "    output_dim=output_dim,\n",
    "    hidden_depth=1,\n",
    "    dropout_prob=custom_dropout_prob,\n",
    ")\n",
    "\n",
    "model_config = models.ConvMLPConfig(\n",
    "    cnn_config=cnn_config,\n",
    "    mlp_config=mlp_config,\n",
    "    spatial_reduction=spatial_reduction,\n",
    "    coord_conv=coord_conv,\n",
    ")\n",
    "\n",
    "optim_config = optimizers.OptimizerConfig(\n",
    "    learning_rate=custom_learning_rate,\n",
    "    weight_decay=custom_weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682e0f24",
   "metadata": {},
   "source": [
    "打印配置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "19f903a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_config: MLPConfig(input_dim=34, hidden_dim=256, output_dim=1, hidden_depth=1, dropout_prob=0.1, activation_fn=<ActivationType.RELU: <class 'torch.nn.modules.activation.ReLU'>>)\n",
      "model_config: ConvMLPConfig(cnn_config=CNNConfig(in_channels=5, blocks=[16, 32, 32], activation_fn=<ActivationType.RELU: <class 'torch.nn.modules.activation.ReLU'>>), mlp_config=MLPConfig(input_dim=34, hidden_dim=256, output_dim=1, hidden_depth=1, dropout_prob=0.1, activation_fn=<ActivationType.RELU: <class 'torch.nn.modules.activation.ReLU'>>), spatial_reduction=<SpatialReduction.SPATIAL_SOFTMAX: <class 'ibc.modules.SpatialSoftArgmax'>>, coord_conv=True)\n",
      "optim_config: OptimizerConfig(learning_rate=0.001, weight_decay=0.0001, beta1=0.9, beta2=0.999, lr_scheduler_step=100, lr_scheduler_gamma=0.99)\n",
      "The network structure is: \n",
      " ConvMLP(\n",
      "  (cnn): CNN(\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(5, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ResidualBlock(\n",
      "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ResidualBlock(\n",
      "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ResidualBlock(\n",
      "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (activation): ReLU()\n",
      "  )\n",
      "  (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (reducer): SpatialSoftArgmax()\n",
      "  (mlp): MLP(\n",
      "    (net): Sequential(\n",
      "      (0): Linear(in_features=34, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "The whole network has 66001 parameters\n"
     ]
    }
   ],
   "source": [
    "print(\"mlp_config:\", mlp_config)\n",
    "print(\"model_config:\", model_config)\n",
    "print(\"optim_config:\", optim_config)\n",
    "net = models.ConvMLP(model_config)\n",
    "print(\"The network structure is: \\n\", net)\n",
    "print(\"The whole network has {} parameters\".format(sum(p.numel() for p in net.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e241f7",
   "metadata": {},
   "source": [
    "创建训练进程："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8a51f",
   "metadata": {},
   "source": [
    "虽然将训练细节在下面已经实现了，但是还需要`train_state`来保存checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54d6b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "train_state: trainer.TrainStateProtocol\n",
    "if policy_type == trainer.PolicyType.EXPLICIT:\n",
    "    train_state = trainer.ExplicitTrainState.initialize(\n",
    "        model_config=model_config,\n",
    "        optim_config=optim_config,\n",
    "        device_type=\"cuda\",\n",
    "    )\n",
    "else:\n",
    "    target_bounds = train_dataloader.dataset.get_target_bounds()\n",
    "    stochastic_optim_config = optimizers.DerivativeFreeConfig(\n",
    "        bounds=target_bounds,\n",
    "        train_samples=128,\n",
    "    )\n",
    "\n",
    "    train_state = trainer.ImplicitTrainState.initialize(\n",
    "        model_config=model_config,\n",
    "        optim_config=optim_config,\n",
    "        stochastic_optim_config=stochastic_optim_config,\n",
    "        device_type=\"cuda\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba657c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device_type = \"cuda\"\n",
    "\n",
    "device = torch.device(device_type if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# define model\n",
    "model = models.EBMConvMLP(config=model_config)\n",
    "model.to(device)\n",
    "\n",
    "# use adam optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=optim_config.learning_rate,\n",
    "    weight_decay=optim_config.weight_decay,\n",
    "    betas=(optim_config.beta1, optim_config.beta2),\n",
    ")\n",
    "\n",
    "# learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=optim_config.lr_scheduler_step,\n",
    "    gamma=optim_config.lr_scheduler_gamma,\n",
    ")\n",
    "\n",
    "stochastic_optimizer = optimizers.DerivativeFreeOptimizer.initialize(\n",
    "    stochastic_optim_config,\n",
    "    device_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab74043",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c4d56a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ibc.experiment import Experiment, TensorboardLogData\n",
    "experiment = Experiment(\n",
    "    identifier = experiment_name, # custom experiment name\n",
    ").assert_new()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "43e25337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]/tmp/ipykernel_4010592/3031435480.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tensor = torch.tensor(input).to(device)\n",
      "/tmp/ipykernel_4010592/3031435480.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_tensor = torch.tensor(target).to(device)\n",
      "100%|██████████| 2000/2000 [03:00<00:00, 11.06it/s]\n"
     ]
    }
   ],
   "source": [
    "steps = 0\n",
    "for epoch in tqdm(range(2000)):\n",
    "    if not steps % checkpoint_every_n_steps:\n",
    "        experiment.save_checkpoint(train_state, step=steps)\n",
    "\n",
    "    if not steps % eval_every_n_steps:\n",
    "        test_log_data = train_state.evaluate(test_dataloader)\n",
    "        experiment.log(test_log_data, step=steps)\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        \n",
    "        model.train()\n",
    "        input, target = batch \n",
    "\n",
    "        input_tensor = torch.tensor(input).to(device)\n",
    "        target_tensor = torch.tensor(target).to(device)\n",
    "\n",
    "        # Generate N negatives, one for each element in the batch: (B, N, D).\n",
    "        negatives = stochastic_optimizer.sample(input_tensor.size(0), model)\n",
    "\n",
    "        # Merge target and negatives: (B, N+1, D).\n",
    "        targets = torch.cat([target_tensor.unsqueeze(dim=1), negatives], dim=1)\n",
    "\n",
    "        # Generate a random permutation of the positives and negatives.\n",
    "        permutation = torch.rand(targets.size(0), targets.size(1)).argsort(dim=1)\n",
    "        targets = targets[torch.arange(targets.size(0)).unsqueeze(-1), permutation]\n",
    "\n",
    "        # Get the original index of the positive. This will serve as the class label for the loss.\n",
    "        ground_truth = (permutation == 0).nonzero()[:, 1].to(device)\n",
    "\n",
    "        # For every element in the mini-batch, there is 1 positive for which the EBM\n",
    "        # should output a low energy value, and N negatives for which the EBM should output high energy values.\n",
    "        energy = model(input_tensor, targets)\n",
    "\n",
    "        # Interpreting the energy as a negative logit, we can apply a cross entropy loss to train the EBM.\n",
    "        logits = -1.0 * energy\n",
    "        loss = F.cross_entropy(logits, ground_truth)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        steps += 1  # ensure other moduels run\n",
    "        \n",
    "        train_log_data = TensorboardLogData(\n",
    "            scalars={\n",
    "                \"train/loss\": loss.item(),\n",
    "                \"train/learning_rate\": scheduler.get_last_lr()[0],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Log to tensorboard.\n",
    "        if not steps % log_every_n_steps:\n",
    "            experiment.log(train_log_data, step=steps)\n",
    "\n",
    "# Save one final checkpoint.\n",
    "experiment.save_checkpoint(train_state, step=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510af043",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7b7269c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import pathlib\n",
    "\n",
    "from ibc.dataset import CoordinateRegression\n",
    "from plot import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f1ad36c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class Args:\n",
    "    # experiment_name: experiment_name  # drop了，在后面的代码直接指定\n",
    "    plot_dir: str = \"assets\"\n",
    "    dpi: int = 200\n",
    "    threshold: float = 140\n",
    "\n",
    "dataset_test = test_dataloader.dataset\n",
    "dataset_train = train_dataloader.dataset\n",
    "assert isinstance(dataset_test, CoordinateRegression)\n",
    "assert isinstance(dataset_train, CoordinateRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef1a99d",
   "metadata": {},
   "source": [
    "推理代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96b27b1",
   "metadata": {},
   "source": [
    "推理的一些参数如下：\n",
    "- `noise_scale`: float = 0.33\n",
    "- `noise_shrink`: float = 0.5\n",
    "- `iters`: int = 3\n",
    "- `train_samples`: int = 256\n",
    "- `inference_samples`: int = 2 ** 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d72f8d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size = (32768, 2)\n",
      "samples.shape:  torch.Size([2, 16384, 2])\n"
     ]
    }
   ],
   "source": [
    "noise_scale = stochastic_optim_config.noise_scale\n",
    "# Make sure bounds tensor matches the dtype of the samples and model (float32)\n",
    "bounds = torch.as_tensor(stochastic_optimizer.bounds, dtype=torch.float32, device=device)\n",
    "\n",
    "size = (input.to(device).size(0) * stochastic_optimizer.inference_samples, stochastic_optimizer.bounds.shape[1])\n",
    "print(\"size =\", size)\n",
    "\n",
    "samples = np.random.uniform(stochastic_optimizer.bounds[0, :], stochastic_optimizer.bounds[1, :], size=size)\n",
    "# Use float32 numpy -> torch conversion to match model dtype (float32)\n",
    "samples = torch.as_tensor(samples.astype(np.float32), dtype=torch.float32, device=device)\n",
    "samples = samples.reshape(input.to(device).size(0), stochastic_optim_config.inference_samples, -1)\n",
    "\n",
    "print(\"samples.shape: \", samples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc8cc58",
   "metadata": {},
   "source": [
    "evaluate前的准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f89cceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scale = stochastic_optim_config.noise_scale\n",
    "# Make sure bounds tensor matches the dtype of the samples and model (float32)\n",
    "bounds = torch.as_tensor(stochastic_optimizer.bounds, dtype=torch.float32, device=device)\n",
    "\n",
    "total_mse = 0.0\n",
    "num_small_err = 0\n",
    "pixel_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ce57fff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]/tmp/ipykernel_4010592/2213760119.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tensor = torch.tensor(input).to(device)\n",
      "100%|██████████| 63/63 [00:01<00:00, 54.01it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(test_dataloader):\n",
    "    input, target = batch\n",
    "    input_tensor = torch.tensor(input).to(device)\n",
    "\n",
    "    size = (input.to(device).size(0) * stochastic_optimizer.inference_samples, stochastic_optimizer.bounds.shape[1])\n",
    "\n",
    "    samples = np.random.uniform(stochastic_optimizer.bounds[0, :], stochastic_optimizer.bounds[1, :], size=size)\n",
    "    # Use float32 numpy -> torch conversion to match model dtype (float32)\n",
    "    samples = torch.as_tensor(samples.astype(np.float32), dtype=torch.float32, device=device)\n",
    "    samples = samples.reshape(input.to(device).size(0), stochastic_optim_config.inference_samples, -1)\n",
    "\n",
    "    model.eval()    # switch model to \"evaluation mode\"    \n",
    "    # execute infer\n",
    "    for i in range(stochastic_optim_config.iters):\n",
    "        # Compute energies.\n",
    "        energies = model(input_tensor, samples)\n",
    "        probs = F.softmax(-1.0 * energies, dim=-1)  # softmax\n",
    "\n",
    "        # Resample with replacement.\n",
    "        idxs = torch.multinomial(probs, stochastic_optimizer.inference_samples, replacement=True)\n",
    "        samples = samples[torch.arange(samples.size(0)).unsqueeze(-1), idxs]\n",
    "\n",
    "        # Add noise and clip to target bounds.\n",
    "        samples = samples + torch.randn_like(samples) * noise_scale\n",
    "        samples = samples.clamp(min=bounds[0, :], max=bounds[1, :])\n",
    "\n",
    "        noise_scale *= stochastic_optimizer.noise_shrink\n",
    "\n",
    "    # Return target with highest probability.\n",
    "    energies = model(input_tensor, samples)\n",
    "    probs = F.softmax(-1.0 * energies, dim=-1)\n",
    "    best_idxs = probs.argmax(dim=-1)\n",
    "    prediction =  samples[torch.arange(samples.size(0)), best_idxs, :].cpu().numpy()\n",
    "\n",
    "    target = target.cpu().numpy()\n",
    "\n",
    "    # 坐标缩放\n",
    "    pred_unscaled = np.array(prediction)\n",
    "    pred_unscaled += 1\n",
    "    pred_unscaled /= 2\n",
    "    pred_unscaled[:, 0] *= dataset_test.resolution[0] - 1\n",
    "    pred_unscaled[:, 1] *= dataset_test.resolution[1] - 1\n",
    "\n",
    "    target_unscaled = np.array(target)\n",
    "    target_unscaled += 1\n",
    "    target_unscaled /= 2\n",
    "    target_unscaled[:, 0] *= dataset_test.resolution[0] - 1\n",
    "    target_unscaled[:, 1] *= dataset_test.resolution[1] - 1\n",
    "\n",
    "    # error\n",
    "    diff = pred_unscaled - target_unscaled\n",
    "    error = np.asarray(np.linalg.norm(diff, axis=1))\n",
    "    num_small_err += len(error[error < 1.0])\n",
    "    pixel_error.extend(error.tolist())\n",
    "    total_mse += (diff ** 2).mean(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e5faa5",
   "metadata": {},
   "source": [
    "评估loss并绘制预测图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e3b0d019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set MSE: 0.08823486922681331 (496/500)\n",
      "Image be saved to: /home/junbo/ibc-torch/mycode/assets/implicit_pipeline_10.png\n"
     ]
    }
   ],
   "source": [
    "total_test = len(dataset_test)\n",
    "average_mse = total_mse / total_test\n",
    "print(f\"Test set MSE: {average_mse} ({num_small_err}/{total_test})\")\n",
    "\n",
    "test_coords = dataset_test.coordinates\n",
    "train_coords = dataset_train.coordinates\n",
    "\n",
    "# Plot and dump to disk.\n",
    "plot_dir = pathlib.Path(Args.plot_dir)\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "experiment = Experiment(\n",
    "    identifier=experiment.identifier,\n",
    ").assert_exists()\n",
    "\n",
    "plot(\n",
    "    train_coords,\n",
    "    test_coords,\n",
    "    np.asarray(pixel_error),\n",
    "    test_dataloader.dataset.resolution,\n",
    "    plot_dir / f\"{experiment.identifier}.png\",\n",
    "    Args.dpi,\n",
    "    Args.threshold,\n",
    ")\n",
    "\n",
    "current_dir = pathlib.Path.cwd()\n",
    "print(\"Image be saved to:\", current_dir / plot_dir / f\"{experiment.identifier}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
